---
title: "Classify"
author: "Tristan Kleyn"
format: html
editor: visual
---

# Train and test ROCCA classifier models

------------------------------------------------------------------------

## ‚ÑπÔ∏è About this notebook:

This is a Quarto notebook composed of a mix of markdown and R code, designed to facilitate development of acoustic classifier models from output .csv files exported by the ROCCA (Real-time Odontocete Call Classification Algorithm) module in PAMGuard. This specific format is currently the only one usable for this notebook.

**With this notebook, you can:**

-   Load and compile ROCCA acoustic measurements for whistle and click detections in PAMGuard.

-   Visualize your acoustic data by different ROCCA variables and data groupings.

-   Train and test acoustic classifiers for any target variable (e.g. species, location)

-   Save data tables, figures, and Random Forest classifier models (.rds)

-   Apply saved Random Forest classifiers to predict new data

Throughout the notebook, there are many parameters that can be adjusted to tailor the analysis to your specific needs. Any line of code that is adjustable is denoted with this green square üü©. It is advised to not adjust any code without a green square beside it. Different parameters involve different types of inputs. For example, the code cell below contains two adjustable parameters, one a binary variable (TRUE or FALSE) and one a character variable (any text input surrounded quotation marks). Code cells can be run by clicking the green triangle in the top right-hand corner. Try running the code cell below.

```{r}
x <- 'cows are black and white.'

INSERT <- 'Some' #üü©
print_sentence <- FALSE #üü©

if (print_sentence) {
  cat(paste(INSERT, x))
}
```

The following "Setting up" section contains a code cell where general parameters used throughout the notebook can be adjusted. Look out for üü© symbols elsewhere for opportunities to tailor the analysis. Explanations for some parameters are provided within this notebook, while descriptions of all adjustable parameters can be found [here](https://github.com/tristankleyn/ClassifyStuff/tree/master).

------------------------------------------------------------------------

## ‚öôÔ∏è Setting up

The first steps for this analysis are to source the functions needed for the analysis and to read in your .csv formatted data.

**Run the cell below to source required functions:**

```{r}
#| warning: false
#| message: false

suppressWarnings(source('Classify-rocca_functions.R'))
```

**Set your plotting aesthetics by adjusting the parameters listed in the code cell below:**

```{r}
#GENERAL PLOT SETTINGS
point_size <- 2 #üü©
point_transparency <- 0.7 #üü©
line_width <- 1 #üü©
border_col <- NULL #üü©
background <- 'white' #üü©
axis_title_names <- NULL #üü©
axis_title_fontsize <- 12 #üü©
axis_title_margin <- 1 #üü©
axis_tick_fontsize <- 10 #üü©
legend_names <- NULL #üü©
legend_fontsize <- 12 #üü©

#DECISION TREE PLOT SETTINGS
tree_node_pointsize <- 4 #üü©
tree_node_fontsize <- 4 #üü©

#EXPORT SETTINGS
export <- FALSE #üü©
savefolder <- 'results04062025-1' #üü©
plot_dims <- c(8,6) #üü©
plot_DPI <- 600 #üü©



```

### Reading in your data

You can either load your data from a nested hierarchy of folders containing RoccaContourStats .csv files or from one single RoccaContourStats .csv files. The former option is useful for grouping your data by different categories (e.g. encounters, locations, recordings). If loading data from a single .csv file, the only categorical variables available for analysis will be the EncounterNumber and KnownSpecies stored within the .csv itself. Below is an example of how you can structure a nested hierarchy of .csv files to preserve different types of categorical information in your data:

Before reading in your data using the code below, make sure you specify the following variables:

-   **root_directory** \| folder where your data is located. [Example:]{.underline} "C:/Users/Bob/Desktop/Data"

-   **from_folders** \| set as TRUE or FALSE to indicate whether or not your .csv data is stored in a hierarchical folder structure like the example above.

-   **levels** \| vector of labels for each folder level in your hierarchical structure. If **from_folders** is FALSE, this will default to using the "KnownSpecies" and "EncounterID" variables in your .csv data.

-   **startVar** \| name of the first variable (in terms of column number) in your data. [Example]{.underline}: "FREQMAX"

-   **endVar** \| name of the last variable in your data. [Example:]{.underline} "STEPDUR".

-   **omitVars** \| vector of variables to omit from the analysis. [Example:]{.underline} "DURATION".

-   **filterVars_min** \| list of minimum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=0.1, "FREQMEAN"=1000, "FREQRANGE"=500)

-   **filterVars_max** \| list of maximum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=5.0, "FREQMEAN"=25000, "FREQRANGE"=15000)

**Adjust these parameters below and run the cell to read in your data.**

This cell provides output in two different panels, which you can click between. The first shows a table of all variables identified in your data along with their average values for each category of your first hierarchical variable. The second panels provides a summary of the data loaded.

```{r}
root_directory <- "UKData" #üü©
from_folders <- TRUE #üü©
levels <- c('species', 'location', 'encounter', 'recording') #üü©

vocType = 'whistle' #üü©
omitVars <- c('DCQUARTER1MEAN', 'DCQUARTER2MEAN', 'DCQUARTER3MEAN',
              'DCQUARTER4MEAN', 'DCMEAN', 'DCSTDDEV', 'RMSSIGNAL', 'OVERLAP') #üü©

filterVars_min <- list() #üü©
filterVars_max <- list() #üü©

info <- loadDataFromHier(root_directory, from_folders=from_folders, 
                         levels=levels, vocType=vocType, omitVars=omitVars,
                         filterVarsMin = filterVars_min,
                         filterVarsMax = filterVars_max)

allData <- info[[1]]
variables <- info[[2]]

```

------------------------------------------------------------------------

## üìä Explore your data

**Customize and run the cell below to visualize your data according to different variables.**

The following parameters can be adjusted:

-   **VARIABLE1** \| name of first selected variable to include in plot.

-   **VARIABLE2** \| name of second selected variable to include in plot. If you only want to analyse one variable, leave VARIABLE2 as NULL.

-   **targetVar** \| variable to color-code plot by (grouping variable)

-   **alpha** \| transparency of scatter points (0-1)

-   **size** \| size of scatter points

-   **export** \| save plots to folder (TRUE or FALSE)

-   **resultsFolder** \| specific folder to save plots to. To create new folder, leave resultsFolder as NULL.

```{r}
#| fig-height: 7 #üü©
#| fig-width: 10 #üü©
VARIABLE1 <- 'FREQBEG' #üü©
VARIABLE2 <- 'FREQEND' #üü©
targetVar <- 'species' #üü©

dataPlot(d = allData, 
         variables = list('x' = VARIABLE1, 'y' = VARIABLE2, 'group' = targetVar),
         point_size = point_size, 
         point_transparency = point_transparency, 
         line_width = line_width, 
         axis_title_names = c('Start Frequency (Hz)', 'End Frequency (Hz)'),
         axis_title_fontsize = 16,
         axis_title_margin = 12,
         axis_tick_fontsize = 13,
         legend_fontsize = 14,
         legend_names = c('Common', 'Pilot whale', 'Bottlenose'),
         border_col = NULL,
         export = TRUE, 
         savefolder = savefolder,
         plot_dims = c(16,12),
         plot_DPI = plot_DPI)
```

------------------------------------------------------------------------

## üöÄ Train and test classifier models

**Train a classifier model on your data.** The next code cell is for training a classifier model using your data. Here, several parameters can be adjusted to tweak the design and training of your model:

-   **targetVar** \| target variable for classification. [Example:]{.underline} 'species'

-   **groupVar** \| variable for grouping data prior to train-test split. [Example:]{.underline} 'encounter'

-   **groupMax** \| maximum number of training examples per group. [Example:]{.underline} 50

-   **pruneTrain** \| proportion (0-1) of training data to prune out using PCA-based pruning (see supplementary information for more detail). [Example:]{.underline} 0.10

-   **minScore** \| minimum decision score (0-1) for keeping individual classifications (see supplementary information for more detail). [Example:]{.underline} 0.05

-   **select** \| vector of select groups to restrict training and testing to (leave as c() to not select any). [Example:]{.underline} c("Location1", "Location2")

-   **omit** \| list of categories for any hierarchical level in data to exclude from classifier training and testing. [Example:]{.underline} list('species'=c('SpeciesA"), 'location'=c('Location2", "Location3"))

```{r}
#| warning: false

# CLASSIFICATION SETUP
targetVar <- 'species' #üü©
groupVar <- 'encounter' #üü©
nMax <- 25 #üü©
pruneTrain <- 0 #üü©
minScore <- 0.02 #üü©
selectGroups <- c() #üü©
omitGroups <- list() #üü©

nTrees <- 500 #üü©
mTry <- NULL #üü©
nodeSize <- 25 #üü©

info <- classifyData(allData, vars=variables, targetVar=targetVar, 
                     groupVar=groupVar, nMax=nMax, prune=pruneTrain, 
                     nTrees=nTrees, mtry=mTry, node_size=nodeSize,
                     minScore=minScore, select_groups=selectGroups, 
                     omit=omitGroups)


groupPreds <- info$groupPreds
allPreds <- info$allPreds
model <- info$model
```

**Run the cell below to output a summary of your classifier training and testing.**

Again, the output is shown in two panels below. The first panel gives a confusion matrix table of true labels against predicted labels, where correct classifications are shown along the diagonal. The second panel gives a written summary of overall and mean classification accuracy.

-   **minGroupScore \|** minimum decision threshold for group predictions.

-   **Classifications discarded \|** percentage of classifications below score threshold and discarded.

-   **Overall accuracy \|** percentage of total classifications that are correct.

-   **Mean species accuracy \|** average accuracy (percentage correct classification) across species.

```{r}
minGroupScore <- 0.0 #üü©
summResults(groupPreds, targetVar=targetVar, minScore=minGroupScore)
```

**Visualize classifier performance by running the below cell.**

The three output panels here show different aspect of the classification results. The first (left) panel shows variable importance in terms of Gini impurity decrease of the 15 most important variables used by the model. The second (middle) panel shows a scatter plot of classification accuracy against the % of predictions discarded using increasing minimum decision score thresholds. The third (right) panel shows overall accuracy, mean accuracy, and % of predictions classified at increasing minimum decision score thresholds.

```{r}
#| fig-height: 6 #üü©
#| fig-width: 9 #üü©

plot_info <- plotResults(groupPreds, allPreds,
                         model=model, targetVar=targetVar, thrMax=0.10,
                         point_size=3, 
                         point_transparency=0.8,
                         line_width=line_width,
                         axis_title_fontsize=14,
                         axis_title_margin=12,
                         axis_tick_fontsize=12,
                         legend_fontsize=14,
                         border_col = NULL,
                         export = TRUE,
                         savefolder = savefolder,
                         plot_dims = c(16,12),
                         plot_DPI = 600)

```

```{r}
#| fig-width: 30 #üü©      
#| fig-height: 15 #üü©    
#| out-width: "100%" #üü© 
#| out-height: "auto" #üü© 

trees_to_plot <- 1:10 #üü©

for (index in trees_to_plot) {
  plot_tree <- plotDecisionTree(model, 
                                tree_num = index, 
                                nodeSize = tree_node_pointsize, 
                                nodeText = tree_node_fontsize, 
                                labelText = tree_node_fontsize,
                                show_plot=FALSE,
                                export = TRUE,
                                savefolder = savefolder,
                                plot_dims = c(8,6),
                                plot_DPI = 600)
}

```

------------------------------------------------------------------------

## üîé Apply saved classifiers to new data

```{r}
data_dir <- 'pamguard/detections060625'
from_folders <- TRUE #üü©
levels <- c('location', 'recording') #üü©

vocType = 'whistle' #üü©
omitVars <- c('DCQUARTER1MEAN', 'DCQUARTER2MEAN', 'DCQUARTER3MEAN',
              'DCQUARTER4MEAN', 'DCMEAN', 'DCSTDDEV', 'RMSSIGNAL', 'OVERLAP') #üü©

filterVars_min <- list() #üü©
filterVars_max <- list() #üü©

info <- loadDataFromHier(data_dir, from_folders=from_folders, 
                         levels=levels, vocType=vocType, omitVars=omitVars,
                         filterVarsMin = filterVars_min,
                         filterVarsMax = filterVars_max)

allData <- info[[1]]
variables <- info[[2]]
```

```{r}
load_model <- readRDS('results04062025-1/classifier.rds')

# CLASSIFY NEW DATA
groupVar <- 'recording' #üü©
minScore <- 0.0 #üü©
selectGroups <- c() #üü©
omitGroups <- list() #üü©

info <- classifyData(allData, 
                     vars = variables, 
                     targetVar = NULL, 
                     load_model = load_model,
                     groupVar = groupVar, 
                     minScore = minScore, 
                     select_groups = selectGroups, 
                     omit = omitGroups)


groupPreds <- info$groupPreds
allPreds <- info$allPreds
model <- info$model
data.table(groupPreds)
```

```{r}
#| warning: false
#| message: false
#| fig-height: 4 #üü©
#| fig-width: 8 #üü©

select_groups <- NULL #üü©

if (is.null(select_groups)) {
  select_groups <- unique(allPreds[[groupVar]])
}

for (select_group in select_groups) {
  showClassifications(allPreds,
                    load_model = load_model,
                    select_group = select_group,
                    cumulative = TRUE,
                    point_size = 2.5,
                    point_transparency = 0.5,
                    line_width = line_width,
                    axis_title_fontsize = 16,
                    axis_title_margin = 12,
                    axis_tick_fontsize = 13,
                    legend_fontsize = 14,
                    border_col = border_col,
                    background = background)
}

```
