---
title: "Classify"
author: "Tristan Kleyn"
format: html
editor: visual
---

# Train and test ROCCA classifier models

------------------------------------------------------------------------

## â„¹ï¸ About this notebook:

This is a Quarto notebook composed of a mix of markdown and R code, designed to facilitate development of acoustic classifier models from output .csv files exported by the ROCCA (Real-time Odontocete Call Classification Algorithm) module in PAMGuard. This specific format is currently the only one usable for this notebook. While it is not a pre-requisite for using this notebook, some familiarity with programming in R will help to better understand how to use this script and adjust parameters. A crash course on basic R concepts can be found [here](https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf) and an [â” FAQs/Troubleshooting] section is available at the bottom of the script to assist with common issues.

**This notebook is divided into the following sections:**

-   [âš™ï¸ Setting up] / adjust general settings and load in your ROCCA data

-   [ğŸ“Š Explore your data] / visualize your loaded data, export data plots

-   [ğŸš€ Train and test classifier models] / train and test Random Forest classifier models

-   [ğŸ” Apply saved classifiers to new data] / use saved classifiers on new ROCCA data

-   [â” FAQs/Troubleshooting] / common issues and fixes

Throughout the notebook, there are parameters that can be adjusted to tailor the analysis to your specific needs. Any line of code that is adjustable in this way is denoted with this green square ğŸŸ©. It is advised to not adjust lines of code without a green square beside them. Different parameters involve different types of inputs. For example, the code cell below contains two adjustable parameters, one a binary variable (TRUE or FALSE) and one a character variable (any text input surrounded quotation marks). Code cells can be run by clicking the green triangle in the top right-hand corner.

**Try running the code cell below and adjusting its parameters to see changes in its output.**

```{r}
x <- 'cows are black and white.'

INSERT <- 'Some' #ğŸŸ©
print_sentence <- TRUE #ğŸŸ©

if (print_sentence) {
  cat(paste(INSERT, x))
}
```

The following "Setting up" section contains a code cell where general parameters used throughout the notebook can be adjusted. Look out for ğŸŸ© symbols elsewhere for opportunities to tailor the analysis. Explanations for some parameters are provided within this notebook, while descriptions of all adjustable parameters can be found [here](https://github.com/tristankleyn/ClassifyStuff/tree/master).

â• **IMPORTANT: Your IDE (RStudio, VS Code, etc.) will likely prompt you to install or update packages prior to using this script. You must do this in order for the script to run correctly. To check whether the required packages are installed on your system, run the cell below:**

```{r}
packages_to_install <- readLines('requirements.txt')
packages_to_install <- packages_to_install[nchar(packages_to_install) > 0]
packages_to_install <- packages_to_install[!grepl("^#", packages_to_install)]

# Loop through the packages, install if not present
for (pkg in packages_to_install) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    message(paste("Package '", pkg, "' not found. Installing now...", sep = ""))
    install.packages(pkg, dependencies = TRUE)
    message(paste("Package '", pkg, "' installed successfully.", sep = ""))
  } else {
    message(paste("Package '", pkg, "' is already installed.", sep = ""))
  }
}

message("\nAll specified packages have been checked. Missing packages were installed.")
```

------------------------------------------------------------------------

## âš™ï¸ Setting up

Once you've confirmed that you have required packages installed, you are ready to set up the notebook for the analysis. The first steps are to source the functions needed for the analysis and to read in your .csv formatted data.

**Run the cell below to source required functions:**

```{r}
#| warning: false
#| message: false

suppressWarnings(source('Classify-rocca_functions.R'))
```

**Use this cell below to customize aesthetics for plots (see** [here](https://github.com/tristankleyn/ClassifyStuff/tree/master) **for definitions):**

```{r}
#GENERAL PLOT SETTINGS
point_size <- 2 #ğŸŸ©
point_transparency <- 0.7 #ğŸŸ©
line_width <- 1 #ğŸŸ©
border_col <- NULL #ğŸŸ©
background <- 'white' #ğŸŸ©
axis_title_names <- NULL #ğŸŸ©
axis_title_fontsize <- 12 #ğŸŸ©
axis_title_margin <- 1 #ğŸŸ©
axis_tick_fontsize <- 10 #ğŸŸ©
legend_names <- NULL #ğŸŸ©
legend_fontsize <- 12 #ğŸŸ©

#DECISION TREE PLOT SETTINGS
tree_node_pointsize <- 4 #ğŸŸ©
tree_node_fontsize <- 4 #ğŸŸ©

#EXPORT SETTINGS
export <- FALSE #ğŸŸ©
savefolder <- NULL #ğŸŸ©
plot_dims <- c(10,7) #ğŸŸ©
plot_DPI <- 600 #ğŸŸ©



```

### Reading in your data

You can either load your data from a nested hierarchy of folders containing RoccaContourStats .csv files or from one single RoccaContourStats .csv files. The former option is useful for grouping your data by different categories (e.g. encounters, locations, recordings). If loading data from a single .csv file, the only categorical variables available for analysis will be the EncounterNumber and KnownSpecies stored within the .csv itself. Below is an example of how you can structure a nested hierarchy of .csv files to preserve different types of categorical information in your data:

![](img01.PNG){fig-align="center" width="459"}

Before reading in your data using the code below, make sure you specify the following variables:

-   **root_directory** \| folder where your data is located. [Example:]{.underline} "C:/Users/Bob/Desktop/Data"

-   **from_folders** \| set as TRUE or FALSE to indicate whether or not your .csv data is stored in a hierarchical folder structure like the example above.

-   **levels** \| vector of labels for each folder level in your hierarchical structure. If **from_folders** is FALSE, this will default to using the "KnownSpecies" and "EncounterID" variables in your .csv data.

-   **subset** \| optional list for subsetting the dataset, where vectors within list contain levels of specified variables to include in subset. [Example]{.underline}: list('species'=c('Species A', 'Species'B), 'location'='Timbuktu')

-   **omitVars** \| vector of variables to omit from the analysis. [Example:]{.underline} "DURATION".

-   **filterVars_min** \| list of minimum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=0.1, "FREQMEAN"=1000, "FREQRANGE"=500)

-   **filterVars_max** \| list of maximum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=5.0, "FREQMEAN"=25000, "FREQRANGE"=15000)

**Adjust these parameters below and run the cell to read in your data.**

This cell provides output in two different panels, which you can click between. The first shows a table of all variables identified in your data along with their average values for each category of your first hierarchical variable. The second panels provides a summary of the data loaded.

```{r}
root_directory <- "UKData" #ğŸŸ©
from_folders <- TRUE #ğŸŸ©
levels <- c('species', 'location', 'encounter', 'recording') #ğŸŸ©
subset <- NULL

vocType = 'whistle' #ğŸŸ©
omitVars <- c('DCQUARTER1MEAN', 'DCQUARTER2MEAN', 'DCQUARTER3MEAN',
              'DCQUARTER4MEAN', 'DCMEAN', 'DCSTDDEV', 'RMSSIGNAL', 'OVERLAP') #ğŸŸ©

filterVars_min <- list() #ğŸŸ©
filterVars_max <- list() #ğŸŸ©

info <- loadDataFromHier(root_directory, from_folders=from_folders, 
                         levels=levels, subsetting = subset, 
                         vocType=vocType, omitVars=omitVars,
                         filterVarsMin = filterVars_min,
                         filterVarsMax = filterVars_max)

allData <- info[[1]]
variables <- info[[2]]

```

------------------------------------------------------------------------

## ğŸ“Š Explore your data

**Customize and run the cell below to visualize your data according to different variables.**

The following parameters can be adjusted:

-   **VARIABLE1** \| name of first selected variable to include in plot.

-   **VARIABLE2** \| name of second selected variable to include in plot. If you only want to analyse one variable, leave VARIABLE2 as NULL.

-   **targetVar** \| variable to color-code plot by (grouping variable)

-   **axis_title_names** \| optional variable for labelling x and y axes manually e.g. c('BW (Hz)', 'Freq (Hz)')

-   **legend_names** \| optional variable for naming targetVar labels manually e.g. c('Species A', 'Species B')

```{r}
#| fig-height: 7 #ğŸŸ©
#| fig-width: 10 #ğŸŸ©
VARIABLE1 <- 'FREQBEG' #ğŸŸ©
VARIABLE2 <- 'FREQEND' #ğŸŸ©
targetVar <- 'species' #ğŸŸ©

dataPlot(d = allData, 
         variables = list('x' = VARIABLE1, 'y' = VARIABLE2, 'group' = targetVar),
         point_size = point_size, #ğŸŸ©
         point_transparency = point_transparency, #ğŸŸ©
         line_width = line_width, #ğŸŸ©
         axis_title_names = NULL, #ğŸŸ©
         axis_title_fontsize = 16, #ğŸŸ©
         axis_title_margin = 12, #ğŸŸ©
         axis_tick_fontsize = 13, #ğŸŸ©
         legend_fontsize = 14, #ğŸŸ©
         legend_names = NULL, #ğŸŸ©
         border_col = border_col, #ğŸŸ©
         export = export,  #ğŸŸ©
         savefolder = savefolder, #ğŸŸ©
         plot_dims = plot_dims, #ğŸŸ©
         plot_DPI = plot_DPI) #ğŸŸ©
```

------------------------------------------------------------------------

## ğŸš€ Train and test classifier models

**Train a classifier model on your data.** The next code cell is for training a classifier model using your data. Here, several parameters can be adjusted to tweak the design and training of your model:

-   **targetVar** \| target variable for classification. [Example:]{.underline} 'species'

-   **groupVar** \| variable for grouping data prior to train-test split. [Example:]{.underline} 'encounter'

-   **groupMax** \| maximum number of training examples per group. [Example:]{.underline} 50

-   **pruneTrain** \| proportion (0-1) of training data to prune out using PCA-based pruning (see supplementary information for more detail). [Example:]{.underline} 0.10

-   **minScore** \| minimum decision score (0-1) for keeping individual classifications (see supplementary information for more detail). [Example:]{.underline} 0.05

-   **omitGroups** \| vector of select groups (levels of **groupVar**) to exclude from classifier training and testing. [Example:]{.underline} c('encounter001', 'encounter002')

Running the cell below will initiate an iterative process for training and testing classifiers, where each loop of this process involves creating a test set consisting entirely of data from the same group (i.e. a level of your **groupVar** variable) and training set consisting of data not from the test group. A Random Forest classifier is then fitted to the training set and tested on the test set, with the predictions stored before proceeding to the next iteration. A running output shows test groups by their true and predicted labels, with the decision score shown in parentheses.

```{r}
#| warning: false

# CLASSIFICATION SETUP
targetVar <- 'species' #ğŸŸ©
groupVar <- 'encounter' #ğŸŸ©
nMax <- 25 #ğŸŸ©
pruneTrain <- 0 #ğŸŸ©
minScore <- 0.02 #ğŸŸ©
omitGroups <- c() #ğŸŸ©

nTrees <- 500 #ğŸŸ©
mTry <- NULL #ğŸŸ©
nodeSize <- 25 #ğŸŸ©

info <- classifyData(allData, 
                     vars=variables, 
                     targetVar=targetVar, 
                     groupVar=groupVar, 
                     nMax=nMax, 
                     prune=pruneTrain, 
                     nTrees=nTrees,
                     mtry=mTry, 
                     node_size=nodeSize,
                     minScore=minScore, 
                     omit=omitGroups)


groupPreds <- info$groupPreds
allPreds <- info$allPreds
model <- info$model
```

**Run the cell below to output a summary of your classifier training and testing.**

Again, the output is shown in two panels below. The first panel gives a confusion matrix table of true labels against predicted labels, where correct classifications are shown along the diagonal. The second panel gives a written summary of overall and mean classification accuracy.

-   **minGroupScore \|** minimum decision threshold for group predictions.

-   **Classifications discarded \|** percentage of classifications below score threshold and discarded.

-   **Overall accuracy \|** percentage of total classifications that are correct.

-   **Mean species accuracy \|** average accuracy (percentage correct classification) across species.

```{r}
minGroupScore <- 0.0 #ğŸŸ©
summResults(groupPreds, targetVar=targetVar, minScore=minGroupScore)
```

**Visualize classifier performance by running the below cell.**

The three output panels here show different aspect of the classification results. The first (left) panel shows variable importance in terms of Gini impurity decrease of the 15 most important variables used by the model. The second (middle) panel shows a scatter plot of classification accuracy against the % of predictions discarded using increasing minimum decision score thresholds. The third (right) panel shows overall accuracy, mean accuracy, and % of predictions classified at increasing minimum decision score thresholds. Overall accuracy is the percent of correct classifications out of total classifications, while mean accuracy is the mean of the percentages of correct classification across all distinct levels of your target variable (e.g. species).

```{r}
#| fig-height: 6 #ğŸŸ©
#| fig-width: 9 #ğŸŸ©

plot_info <- plotResults(groupPreds, allPreds,
                         model=model, targetVar=targetVar, thrMax = 0.10,
                         point_size=3, #ğŸŸ©
                         point_transparency=0.8, #ğŸŸ©
                         line_width=line_width, #ğŸŸ©
                         axis_title_fontsize=14, #ğŸŸ©
                         axis_title_margin=12, #ğŸŸ©
                         axis_tick_fontsize=12, #ğŸŸ©
                         legend_fontsize=14, #ğŸŸ©
                         border_col = NULL, #ğŸŸ©
                         export = TRUE, #ğŸŸ©
                         savefolder = savefolder, #ğŸŸ©
                         plot_dims = c(16,12), #ğŸŸ©
                         plot_DPI = 600) #ğŸŸ©

```

```{r}
#| fig-width: 30 #ğŸŸ©      
#| fig-height: 15 #ğŸŸ©    
#| out-width: "100%" #ğŸŸ© 
#| out-height: "auto" #ğŸŸ© 

trees_to_plot <- 1:10 #ğŸŸ©

for (index in trees_to_plot) {
  plot_tree <- plotDecisionTree(model, 
                                tree_num = index, 
                                nodeSize = tree_node_pointsize, 
                                nodeText = tree_node_fontsize, 
                                labelText = tree_node_fontsize,
                                show_plot=FALSE,
                                export = TRUE,
                                savefolder = savefolder,
                                plot_dims = c(8,6),
                                plot_DPI = 600)
}

```

------------------------------------------------------------------------

## ğŸ” Apply saved classifiers to new data

Once a classifier is created and saved in .rds format., it can be used to classify new data. Use the code cell below to load in new data from RoccaContourStats.csv files in the same way as previously, using either a hierarchical folder structure (**from_folders** **\<- TRUE**) or a single .csv file (**from_folders** **\<- FALSE**). As with the previous data loading step, there is an option to filter the data loaded by conditions specified by **filterVars_min** and **filterVars_max**.

-   **data_dir** \| base directory containing your new data, either in a nested structure of subfolders or a single RoccaContourStats.csv file.

-   **from_folders** \| set as TRUE or FALSE to indicate whether or not your .csv data is stored in a hierarchical folder structure like the example above.

-   **levels** \| vector of labels for each folder level in your hierarchical structure. If **from_folders** is FALSE, this will default to using the "KnownSpecies" and "EncounterID" variables in your .csv data.

-   **omitVars** \| vector of variables to omit from the analysis. [Example:]{.underline} "DURATION".

-   **filterVars_min** \| list of minimum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=0.1, "FREQMEAN"=1000, "FREQRANGE"=500)

-   **filterVars_max** \| list of maximum limits for selected variables. Enclose variable names in quotation marks or apostrophes. [Example:]{.underline} list("DURATION"=5.0, "FREQMEAN"=25000, "FREQRANGE"=15000)

Running the cell below will output a summary of your new dataset.

```{r}
data_dir <- 'pamguard/detections060625' #ğŸŸ©
from_folders <- TRUE #ğŸŸ©
levels <- c('location', 'recording') #ğŸŸ©

vocType = 'whistle' #ğŸŸ©
omitVars <- c('DCQUARTER1MEAN', 'DCQUARTER2MEAN', 'DCQUARTER3MEAN',
              'DCQUARTER4MEAN', 'DCMEAN', 'DCSTDDEV', 'RMSSIGNAL', 'OVERLAP') #ğŸŸ©

filterVars_min <- list() #ğŸŸ©
filterVars_max <- list() #ğŸŸ©

info <- loadDataFromHier(data_dir, from_folders=from_folders, 
                         levels=levels, vocType=vocType, omitVars=omitVars,
                         filterVarsMin = filterVars_min,
                         filterVarsMax = filterVars_max)

allData <- info[[1]]
variables <- info[[2]]
```

Next, specify the path to the saved .rds classifier model for classifying new data.

-   **groupVar** \| variable for grouping data prior to classification.

-   **minGroupScore** \| minimum decision score below which classifications are discarded.

-   **selectGroups** \| vector of select groups to restrict classification to.

-   **omitGroups** \| vector of select groups to exclude from classification.

```{r}
# CLASSIFY NEW DATA
load_model <- readRDS('myResults/classifier.rds') #ğŸŸ©

groupVar <- 'recording' #ğŸŸ©
minGroupScore <- 0.0 #ğŸŸ©
selectGroups <- c() #ğŸŸ©
omitGroups <- list() #ğŸŸ©

info <- classifyData(allData, 
                     vars = variables, 
                     targetVar = NULL, 
                     load_model = load_model,
                     groupVar = groupVar, 
                     minScore = minGroupScore, 
                     select_groups = selectGroups, 
                     omit = omitGroups)


groupPreds <- info$groupPreds
allPreds <- info$allPreds
model <- info$model
data.table(groupPreds)
```

Visualize classification results for **select_groups** or all groups (leave **select_groups** empty) in the data. The code cell below plots classification probabilities by species over time within each group of detections data. A different plot will be made for each group and shown in a separate output panel. Each point in a plot represents the probability that a classified detection belongs to the species indicated by its color (i.e. vertically aligned points are probabilities of different species for the same detection, adding to 1 if not cumulative).

-   **select_groups** \| vector of groups to show classification results for (leave empty to show all)

-   **cumulative** \| show cumulative classification probabilities by species (TRUE or FALSE)

```{r}
#| warning: false
#| message: false
#| fig-height: 4 #ğŸŸ©
#| fig-width: 8 #ğŸŸ©

select_groups <- c() #ğŸŸ©
cumulative <- FALSE

if (is.null(select_groups)) {
  select_groups <- unique(allPreds[[groupVar]])
}

for (select_group in select_groups) {
  showClassifications(allPreds,
                    load_model = load_model,
                    select_group = select_group,
                    cumulative = cumulative,
                    point_size = 2.5,
                    point_transparency = 0.5,
                    line_width = line_width,
                    axis_title_fontsize = 16,
                    axis_title_margin = 12,
                    axis_tick_fontsize = 13,
                    legend_fontsize = 14,
                    border_col = border_col,
                    background = background,
                    export = TRUE,
                    savefolder = savefolder,
                    plot_dims = plot_dims,
                    plot_DPI = plot_DPI)
}

```

------------------------------------------------------------------------

## â” FAQs/Troubleshooting

**What are classifiers trained to classify groups of data and not individual data points?**

While visualizations and metrics focus on group (i.e. encounter) classification performance, group classifications are merely the averages of all individual classifications within a group. In other words, the classifiers are classifying individual detections before averaging them by group. Averaging leverages larger amounts of information for classification and is often shown to improve results.

**What is a decision score?**

When a classifier predicts a label (i.e. species) for a given data point (i.e. detection), what it is really doing is outputting a single probability (0 to 1) for each possible label. These probabilities always add up to 1 (e.g. 0.24 for A, 0.15 for B, and 0.61 for C). While the label with the highest probability is considered the classified label, the individual probabilities carry informaton regarding the strength of each classification. The decision score is the product of two different metrics: the first is the highest individual probability in a classification (i.e. the probability of the classified label) and the second is the difference in probabilities between the classified label and the second-most-likely label.

**I am getting "no matching files found" when trying to load my data.**

The most likely cause for this is that the **root_directory** that you are specifying either does not exist or does not contain data in the correct format. The fix for the former is to double-check the path of the root directory, which should be located in the same folder as this script. If this directory does exist, then your data is probably not saved in the correct format for loading. Detections from PAMGuard ROCCA need to be saved in RoccaContourStats.csv files and if you are setting **from_folders** to be TRUE, then these .csv files need to be stored in a nested structure of folders where each level is specified with a label as defined by the variable **levels.** If **from_folders** is FALSE and you are storing all your detections in a single RoccaContourStats.csv file, this file should be saved in your **root_directory** folder.

**Why do my exported figures look different from how they look in the notebook output?**

Figures may appear different after being exported due to how you set the plot dimensions **(plot_dims)** and plot dots-per-inch **(plot_DPI)**, as well as how you set figure height and width **(#\| fig-height and #\|fig-width)** in notebook cells. If the content in your plot appears too large in your saved .PNG file, try increasing the dimensions for export.
